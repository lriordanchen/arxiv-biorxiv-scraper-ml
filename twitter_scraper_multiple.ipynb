{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forked from kennethreitz\n",
    "import re\n",
    "from requests_html import HTMLSession, HTML\n",
    "from datetime import datetime\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "\n",
    "def get_tweets(user, pages=25):\n",
    "    \"\"\"Gets tweets for a given user, via the Twitter frontend API.\"\"\"\n",
    "\n",
    "    url = f'https://twitter.com/i/profiles/show/{user}/timeline/tweets?include_available_features=1&include_entities=1&include_new_items_bar=true'\n",
    "    headers = {\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Referer': f'https://twitter.com/{user}',\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8',\n",
    "        'X-Twitter-Active-User': 'yes',\n",
    "        'X-Requested-With': 'XMLHttpRequest'\n",
    "    }\n",
    "\n",
    "    def gen_tweets(pages):\n",
    "        r = session.get(url, headers=headers)\n",
    "\n",
    "        while pages > 0:\n",
    "            try:\n",
    "                html = HTML(html=r.json()['items_html'],\n",
    "                            url='bunk', default_encoding='utf-8')\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    f'Oops! Either \"{user}\" does not exist or is private.')\n",
    "\n",
    "            comma = \",\"\n",
    "            dot = \".\"\n",
    "            tweets = []\n",
    "            for tweet in html.find('.stream-item'):\n",
    "                text = tweet.find('.tweet-text')[0].full_text\n",
    "                tweetId = tweet.find(\n",
    "                    '.js-permalink')[0].attrs['data-conversation-id']\n",
    "                time = datetime.fromtimestamp(\n",
    "                    int(tweet.find('._timestamp')[0].attrs['data-time-ms'])/1000.0)\n",
    "                interactions = [x.text for x in tweet.find(\n",
    "                    '.ProfileTweet-actionCount')]\n",
    "                replies = int(interactions[0].split(\" \")[0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                retweets = int(interactions[1].split(\" \")[\n",
    "                               0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                likes = int(interactions[2].split(\" \")[0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                hashtags = [hashtag_node.full_text for hashtag_node in tweet.find('.twitter-hashtag')]\n",
    "                urls = [url_node.attrs['data-expanded-url'] for url_node in tweet.find('a.twitter-timeline-link:not(.u-hidden)')]\n",
    "                photos = [photo_node.attrs['data-image-url'] for photo_node in tweet.find('.AdaptiveMedia-photoContainer')]\n",
    "                \n",
    "                videos = []\n",
    "                video_nodes = tweet.find(\".PlayableMedia-player\")\n",
    "                for node in video_nodes:\n",
    "                    styles = node.attrs['style'].split()\n",
    "                    for style in styles:\n",
    "                        if style.startswith('background'):\n",
    "                            tmp = style.split('/')[-1]\n",
    "                            video_id = tmp[:tmp.index('.jpg')]\n",
    "                            videos.append({'id': video_id})\n",
    "                tweets.append({'tweetId': tweetId, 'time': time, 'text': text,\n",
    "                               'replies': replies, 'retweets': retweets, 'likes': likes, \n",
    "                               'entries': {\n",
    "                                    'hashtags': hashtags, 'urls': urls,\n",
    "                                    'photos': photos, 'videos': videos\n",
    "                                }\n",
    "                               })\n",
    "\n",
    "            last_tweet = html.find('.stream-item')[-1].attrs['data-item-id']\n",
    "\n",
    "            for tweet in tweets:\n",
    "                if tweet:\n",
    "                    tweet['text'] = re.sub('http', ' http', tweet['text'], 1)\n",
    "                    yield tweet\n",
    "\n",
    "            r = session.get(\n",
    "                url, params = {'max_position': last_tweet}, headers = headers)\n",
    "            pages += -1\n",
    "\n",
    "    yield from gen_tweets(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape from users\n",
    "tweet_df_all = pd.DataFrame([])\n",
    "\n",
    "users = ['nature','Dev_Cell']\n",
    "for i in range(len(users)):\n",
    "    tweet_gen = get_tweets(users[i], pages=1)\n",
    "    # Make df of tweets, extract entries column, make df of entries, add these columns to dataframe\n",
    "    tweet_df = pd.DataFrame(tweet_gen)\n",
    "    entries_list=tweet_df.entries.values.tolist()\n",
    "    entries_df = pd.DataFrame(entries_list)\n",
    "    tweet_df_with_entries = pd.concat([tweet_df, entries_df], axis=1, sort=False)\n",
    "    tweet_df_all = pd.concat([tweet_df_all, tweet_df_with_entries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that don't have urls\n",
    "df_tweet_urls=tweet_df_all[tweet_df_all.astype(str).urls!='[]']\n",
    "df_tweet_urls.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entries</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>tweetId</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>photos</th>\n",
       "      <th>urls</th>\n",
       "      <th>videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://www.nature....</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>On the Nature cover this week: Best laid plans...</td>\n",
       "      <td>2019-03-07 11:04:42</td>\n",
       "      <td>1103597332409528321</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1DDyrIWkAAHzMI.jpg]</td>\n",
       "      <td>[https://www.nature.com/nature/volumes/567/iss...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://go.nature.c...</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>Launching in 2020, Nature Food will publish re...</td>\n",
       "      <td>2019-03-11 09:07:03</td>\n",
       "      <td>1105017275785064448</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1XPWxbWkAA7FID.jpg]</td>\n",
       "      <td>[https://go.nature.com/2C8JiZ9]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'hashtags': ['#ScientistAtWork'], 'urls': ['h...</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>Send us your very best #ScientistAtWork photos...</td>\n",
       "      <td>2019-03-10 18:42:09</td>\n",
       "      <td>1104799617710022657</td>\n",
       "      <td>[#ScientistAtWork]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://go.nature.com/2BPksNK]</td>\n",
       "      <td>[{'id': '_EeiQtEZlJUuSMKC'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://go.nature.c...</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>By repurposing two existing drugs, metformin a...</td>\n",
       "      <td>2019-03-09 11:07:04</td>\n",
       "      <td>1104322703203418112</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1NXpVUWsAErQOz.jpg]</td>\n",
       "      <td>[https://go.nature.com/2tUV1Gs]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://go.nature.c...</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>In this Nature Review article, the authors dis...</td>\n",
       "      <td>2019-03-09 02:07:03</td>\n",
       "      <td>1104186804666798080</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1LcDA1XcAEgycS.jpg]</td>\n",
       "      <td>[https://go.nature.com/2IFA505]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             entries  likes  replies  \\\n",
       "0  {'hashtags': [], 'urls': ['https://www.nature....     56        0   \n",
       "1  {'hashtags': [], 'urls': ['https://go.nature.c...     63        2   \n",
       "2  {'hashtags': ['#ScientistAtWork'], 'urls': ['h...     71        5   \n",
       "3  {'hashtags': [], 'urls': ['https://go.nature.c...    218        2   \n",
       "4  {'hashtags': [], 'urls': ['https://go.nature.c...     98        0   \n",
       "\n",
       "   retweets                                               text  \\\n",
       "0        22  On the Nature cover this week: Best laid plans...   \n",
       "1        31  Launching in 2020, Nature Food will publish re...   \n",
       "2        50  Send us your very best #ScientistAtWork photos...   \n",
       "3        99  By repurposing two existing drugs, metformin a...   \n",
       "4        75  In this Nature Review article, the authors dis...   \n",
       "\n",
       "                 time              tweetId            hashtags  \\\n",
       "0 2019-03-07 11:04:42  1103597332409528321                  []   \n",
       "1 2019-03-11 09:07:03  1105017275785064448                  []   \n",
       "2 2019-03-10 18:42:09  1104799617710022657  [#ScientistAtWork]   \n",
       "3 2019-03-09 11:07:04  1104322703203418112                  []   \n",
       "4 2019-03-09 02:07:03  1104186804666798080                  []   \n",
       "\n",
       "                                              photos  \\\n",
       "0  [https://pbs.twimg.com/media/D1DDyrIWkAAHzMI.jpg]   \n",
       "1  [https://pbs.twimg.com/media/D1XPWxbWkAA7FID.jpg]   \n",
       "2                                                 []   \n",
       "3  [https://pbs.twimg.com/media/D1NXpVUWsAErQOz.jpg]   \n",
       "4  [https://pbs.twimg.com/media/D1LcDA1XcAEgycS.jpg]   \n",
       "\n",
       "                                                urls  \\\n",
       "0  [https://www.nature.com/nature/volumes/567/iss...   \n",
       "1                    [https://go.nature.com/2C8JiZ9]   \n",
       "2                    [https://go.nature.com/2BPksNK]   \n",
       "3                    [https://go.nature.com/2tUV1Gs]   \n",
       "4                    [https://go.nature.com/2IFA505]   \n",
       "\n",
       "                         videos  \n",
       "0                            []  \n",
       "1                            []  \n",
       "2  [{'id': '_EeiQtEZlJUuSMKC'}]  \n",
       "3                            []  \n",
       "4                            []  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_tweet_urls.to_pickle('twitter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping abstracts and/or article paragraphs from websites from urls provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\phantomjs\\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Read in summary (or whole article, if possible)\n",
    "df_tweet_urls['summary'] = ''\n",
    "for ix in range(len(df_tweet_urls)):\n",
    "    this_url = str(df_tweet_urls.urls.iloc[ix]).replace('\"', '').replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    service_args = [\n",
    "    '--proxy=proxy-inst.upf.edu:9090',\n",
    "    '--proxy-type=http',\n",
    "    ]\n",
    "    driver = webdriver.PhantomJS(executable_path='C://Users/lchen/phantomjs/bin/phantomjs', service_args=service_args)\n",
    "    driver.set_window_size(1120, 550)\n",
    "    driver.get(this_url)\n",
    "    #driver.find_element_by_id('search_form_input_homepage').send_keys(\"realpython\")\n",
    "    soup = bs(driver.page_source, 'lxml')\n",
    "    #for i in soup.body:\n",
    "        #print(i)\n",
    "    driver.quit()\n",
    "    summary = ''\n",
    "    if 'sciencmag.org' in this_url:\n",
    "        summary = soup.find_all('span', attrs={'class': 'highwire-journal-article-marker-start'}).text #Science\n",
    "    elif 'nature.com' in this_url and len(soup.find_all('p'))>17:\n",
    "        summary_list = soup.find_all('p')[17:len(soup.find_all('p'))] #Nature\n",
    "        summary_list_text = [x.text for x in summary_list]\n",
    "        summary = ' '.join(summary_list_text)\n",
    "    elif 'cell.com' in this_url:\n",
    "        summary_list = soup.find_all('div', attrs={'class': 'section-paragraph'}) #Cell\n",
    "        summary_list_text = [x.text for x in summary_list]\n",
    "        summary = ' '.join(summary_list_text)\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    df_tweet_urls.summary.iloc[ix]=summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entries</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>tweetId</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>photos</th>\n",
       "      <th>urls</th>\n",
       "      <th>videos</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://www.nature....</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>On the Nature cover this week: Best laid plans...</td>\n",
       "      <td>2019-03-07 11:04:42</td>\n",
       "      <td>1103597332409528321</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1DDyrIWkAAHzMI.jpg]</td>\n",
       "      <td>[https://www.nature.com/nature/volumes/567/iss...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nResearch Highlight\\n | \\n26 February 2019\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://go.nature.c...</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>Launching in 2020, Nature Food will publish re...</td>\n",
       "      <td>2019-03-11 09:07:03</td>\n",
       "      <td>1105017275785064448</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1XPWxbWkAA7FID.jpg]</td>\n",
       "      <td>[https://go.nature.com/2C8JiZ9]</td>\n",
       "      <td>[]</td>\n",
       "      <td>We publish a range of content types including ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'hashtags': ['#ScientistAtWork'], 'urls': ['h...</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>Send us your very best #ScientistAtWork photos...</td>\n",
       "      <td>2019-03-10 18:42:09</td>\n",
       "      <td>1104799617710022657</td>\n",
       "      <td>[#ScientistAtWork]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://go.nature.com/2BPksNK]</td>\n",
       "      <td>[{'id': '_EeiQtEZlJUuSMKC'}]</td>\n",
       "      <td>We’re interested in finding and celebrating ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://go.nature.c...</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>By repurposing two existing drugs, metformin a...</td>\n",
       "      <td>2019-03-09 11:07:04</td>\n",
       "      <td>1104322703203418112</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1NXpVUWsAErQOz.jpg]</td>\n",
       "      <td>[https://go.nature.com/2tUV1Gs]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://go.nature.c...</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>In this Nature Review article, the authors dis...</td>\n",
       "      <td>2019-03-09 02:07:03</td>\n",
       "      <td>1104186804666798080</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D1LcDA1XcAEgycS.jpg]</td>\n",
       "      <td>[https://go.nature.com/2IFA505]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://www.science...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Check out our new @Dev_Cell paper by @DCheeram...</td>\n",
       "      <td>2019-03-01 04:51:59</td>\n",
       "      <td>1101329207827738624</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D0i0yDwV4AAdLmS.jpg]</td>\n",
       "      <td>[https://www.sciencedirect.com/science/article...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'hashtags': ['#CSTxnDev'], 'urls': ['http://b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Developmental biologists! @CellSymposia  Trans...</td>\n",
       "      <td>2019-02-28 20:00:40</td>\n",
       "      <td>1101195498772414464</td>\n",
       "      <td>[#CSTxnDev]</td>\n",
       "      <td>[https://pbs.twimg.com/media/D0g7eE6XcAEjGiF.jpg]</td>\n",
       "      <td>[http://bit.ly/2XsSzUS]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'hashtags': [], 'urls': ['http://ow.ly/YGhJ30...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A Perspective on the use of microfluidics in d...</td>\n",
       "      <td>2019-02-20 19:05:12</td>\n",
       "      <td>1098282434947354624</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[http://ow.ly/YGhJ30nLRSB]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'hashtags': [], 'urls': ['http://ow.ly/U6VH30...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>On the cover, a fox eating spätzle. Read about...</td>\n",
       "      <td>2019-02-20 17:50:20</td>\n",
       "      <td>1098263594024751104</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://pbs.twimg.com/media/Dz3Q6wXXgAEAoKK.jpg]</td>\n",
       "      <td>[http://ow.ly/U6VH30nLRz5]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'hashtags': ['#RNA', '#CSRNA19'], 'urls': ['h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @CellPressNews: Keynote Patrick Cramer @mpi...</td>\n",
       "      <td>2019-02-15 18:15:04</td>\n",
       "      <td>1096457882227363842</td>\n",
       "      <td>[#RNA, #CSRNA19]</td>\n",
       "      <td>[https://pbs.twimg.com/media/DzdmogJWsAAKqJy.jpg]</td>\n",
       "      <td>[http://bit.ly/2GQZd1F]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             entries  likes  replies  \\\n",
       "0  {'hashtags': [], 'urls': ['https://www.nature....     56        0   \n",
       "1  {'hashtags': [], 'urls': ['https://go.nature.c...     63        2   \n",
       "2  {'hashtags': ['#ScientistAtWork'], 'urls': ['h...     71        5   \n",
       "3  {'hashtags': [], 'urls': ['https://go.nature.c...    218        2   \n",
       "4  {'hashtags': [], 'urls': ['https://go.nature.c...     98        0   \n",
       "5  {'hashtags': [], 'urls': ['https://www.science...    100        0   \n",
       "6  {'hashtags': ['#CSTxnDev'], 'urls': ['http://b...      1        0   \n",
       "7  {'hashtags': [], 'urls': ['http://ow.ly/YGhJ30...      3        0   \n",
       "8  {'hashtags': [], 'urls': ['http://ow.ly/U6VH30...     34        0   \n",
       "9  {'hashtags': ['#RNA', '#CSRNA19'], 'urls': ['h...      1        0   \n",
       "\n",
       "   retweets                                               text  \\\n",
       "0        22  On the Nature cover this week: Best laid plans...   \n",
       "1        31  Launching in 2020, Nature Food will publish re...   \n",
       "2        50  Send us your very best #ScientistAtWork photos...   \n",
       "3        99  By repurposing two existing drugs, metformin a...   \n",
       "4        75  In this Nature Review article, the authors dis...   \n",
       "5        28  Check out our new @Dev_Cell paper by @DCheeram...   \n",
       "6         1  Developmental biologists! @CellSymposia  Trans...   \n",
       "7         1  A Perspective on the use of microfluidics in d...   \n",
       "8         9  On the cover, a fox eating spätzle. Read about...   \n",
       "9         0  RT @CellPressNews: Keynote Patrick Cramer @mpi...   \n",
       "\n",
       "                 time              tweetId            hashtags  \\\n",
       "0 2019-03-07 11:04:42  1103597332409528321                  []   \n",
       "1 2019-03-11 09:07:03  1105017275785064448                  []   \n",
       "2 2019-03-10 18:42:09  1104799617710022657  [#ScientistAtWork]   \n",
       "3 2019-03-09 11:07:04  1104322703203418112                  []   \n",
       "4 2019-03-09 02:07:03  1104186804666798080                  []   \n",
       "5 2019-03-01 04:51:59  1101329207827738624                  []   \n",
       "6 2019-02-28 20:00:40  1101195498772414464         [#CSTxnDev]   \n",
       "7 2019-02-20 19:05:12  1098282434947354624                  []   \n",
       "8 2019-02-20 17:50:20  1098263594024751104                  []   \n",
       "9 2019-02-15 18:15:04  1096457882227363842    [#RNA, #CSRNA19]   \n",
       "\n",
       "                                              photos  \\\n",
       "0  [https://pbs.twimg.com/media/D1DDyrIWkAAHzMI.jpg]   \n",
       "1  [https://pbs.twimg.com/media/D1XPWxbWkAA7FID.jpg]   \n",
       "2                                                 []   \n",
       "3  [https://pbs.twimg.com/media/D1NXpVUWsAErQOz.jpg]   \n",
       "4  [https://pbs.twimg.com/media/D1LcDA1XcAEgycS.jpg]   \n",
       "5  [https://pbs.twimg.com/media/D0i0yDwV4AAdLmS.jpg]   \n",
       "6  [https://pbs.twimg.com/media/D0g7eE6XcAEjGiF.jpg]   \n",
       "7                                                 []   \n",
       "8  [https://pbs.twimg.com/media/Dz3Q6wXXgAEAoKK.jpg]   \n",
       "9  [https://pbs.twimg.com/media/DzdmogJWsAAKqJy.jpg]   \n",
       "\n",
       "                                                urls  \\\n",
       "0  [https://www.nature.com/nature/volumes/567/iss...   \n",
       "1                    [https://go.nature.com/2C8JiZ9]   \n",
       "2                    [https://go.nature.com/2BPksNK]   \n",
       "3                    [https://go.nature.com/2tUV1Gs]   \n",
       "4                    [https://go.nature.com/2IFA505]   \n",
       "5  [https://www.sciencedirect.com/science/article...   \n",
       "6                            [http://bit.ly/2XsSzUS]   \n",
       "7                         [http://ow.ly/YGhJ30nLRSB]   \n",
       "8                         [http://ow.ly/U6VH30nLRz5]   \n",
       "9                            [http://bit.ly/2GQZd1F]   \n",
       "\n",
       "                         videos  \\\n",
       "0                            []   \n",
       "1                            []   \n",
       "2  [{'id': '_EeiQtEZlJUuSMKC'}]   \n",
       "3                            []   \n",
       "4                            []   \n",
       "5                            []   \n",
       "6                            []   \n",
       "7                            []   \n",
       "8                            []   \n",
       "9                            []   \n",
       "\n",
       "                                             summary  \n",
       "0  \\nResearch Highlight\\n | \\n26 February 2019\\n ...  \n",
       "1  We publish a range of content types including ...  \n",
       "2  We’re interested in finding and celebrating ar...  \n",
       "3                                                     \n",
       "4                                                     \n",
       "5                                                     \n",
       "6                                                     \n",
       "7                                                     \n",
       "8                                                     \n",
       "9                                                     "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet_urls.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_urls.to_pickle('twitter_with_summaries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
